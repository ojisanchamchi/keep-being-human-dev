"use strict";(self.webpackChunkkeep_being_human_dev=self.webpackChunkkeep_being_human_dev||[]).push([[85876],{28365:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"ruby/xml/advanced/sax_streaming_large_xml","title":"sax_streaming_large_xml","description":"\ud83d\udce5 Leveraging SAX Parsing for Large XML Streams","source":"@site/docs/ruby/xml/advanced/sax_streaming_large_xml.md","sourceDirName":"ruby/xml/advanced","slug":"/ruby/xml/advanced/sax_streaming_large_xml","permalink":"/keep-being-human-dev/docs/ruby/xml/advanced/sax_streaming_large_xml","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ruby/xml/advanced/sax_streaming_large_xml.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"high_performance_ox","permalink":"/keep-being-human-dev/docs/ruby/xml/advanced/high_performance_ox"},"next":{"title":"xpath_with_namespaces","permalink":"/keep-being-human-dev/docs/ruby/xml/advanced/xpath_with_namespaces"}}');var t=r(23420),s=r(65404);const i={},o=void 0,c={},l=[{value:"\ud83d\udce5 Leveraging SAX Parsing for Large XML Streams",id:"-leveraging-sax-parsing-for-large-xml-streams",level:2}];function m(e){const n={code:"code",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"-leveraging-sax-parsing-for-large-xml-streams",children:"\ud83d\udce5 Leveraging SAX Parsing for Large XML Streams"}),"\n",(0,t.jsxs)(n.p,{children:["When working with massive XML files, loading the entire document into memory can be prohibitive. Using Nokogiri\u2019s SAX parser lets you process elements one by one in a streaming fashion, keeping memory usage minimal. Define a custom handler to respond to events like ",(0,t.jsx)(n.code,{children:"start_element"}),", ",(0,t.jsx)(n.code,{children:"characters"}),", and ",(0,t.jsx)(n.code,{children:"end_element"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ruby",children:"require 'nokogiri'\n\nclass StreamHandler < Nokogiri::XML::SAX::Document\n  def start_element(name, attrs = [])\n    @current = name\n    @attrs = Hash[*attrs.flatten]\n  end\n\n  def characters(string)\n    return if string.strip.empty?\n    puts \"Element: #{@current}, Text: #{string.strip}\"\n  end\n\n  def end_element(name)\n    # finalize or clean up per-element logic here\n  end\nend\n\nparser = Nokogiri::XML::SAX::Parser.new(StreamHandler.new)\nparser.parse(File.open('huge_data.xml'))\n"})}),"\n",(0,t.jsx)(n.p,{children:"This approach fires callbacks per node, so you can filter, transform, or store data incrementally without high memory overhead."})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(m,{...e})}):m(e)}},65404:(e,n,r)=>{r.d(n,{R:()=>i,x:()=>o});var a=r(36672);const t={},s=a.createContext(t);function i(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);