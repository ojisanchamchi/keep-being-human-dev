---
slug: ruby-concurrency-mutexes-tu-co-ban-den-nang-cao
title: "Ruby Concurrency & Mutexes: T·ª´ C∆° B·∫£n ƒê·∫øn N√¢ng Cao - H∆∞·ªõng D·∫´n To√†n Di·ªán"
authors: [admin]
tags: [ruby, concurrency, mutex, threading, synchronization, performance, parallel]
---

# Ruby Concurrency & Mutexes: T·ª´ C∆° B·∫£n ƒê·∫øn N√¢ng Cao

Concurrency (ƒë·ªìng th·ªùi) l√† m·ªôt trong nh·ªØng ch·ªß ƒë·ªÅ ph·ª©c t·∫°p nh·∫•t trong l·∫≠p tr√¨nh, nh∆∞ng c≈©ng l√† ch√¨a kh√≥a ƒë·ªÉ t·∫°o ra nh·ªØng ·ª©ng d·ª•ng Ruby hi·ªáu su·∫•t cao. Trong b√†i vi·∫øt n√†y, ch√∫ng ta s·∫Ω kh√°m ph√° t·ª´ nh·ªØng kh√°i ni·ªám c∆° b·∫£n v·ªÅ threads v√† mutexes ƒë·∫øn c√°c k·ªπ thu·∫≠t n√¢ng cao nh∆∞ lock striping v√† fair mutexes.

<!--truncate-->

## T·∫°i Sao C·∫ßn Concurrency?

Tr∆∞·ªõc khi ƒëi v√†o chi ti·∫øt, h√£y hi·ªÉu t·∫°i sao concurrency l·∫°i quan tr·ªçng:

- **TƒÉng hi·ªáu su·∫•t**: T·∫≠n d·ª•ng multi-core processors
- **C·∫£i thi·ªán responsiveness**: UI kh√¥ng b·ªã ƒë√≥ng bƒÉng khi x·ª≠ l√Ω t√°c v·ª• n·∫∑ng
- **X·ª≠ l√Ω I/O hi·ªáu qu·∫£**: Kh√¥ng ch·ªù ƒë·ª£i network/disk operations
- **Scalability**: X·ª≠ l√Ω nhi·ªÅu requests ƒë·ªìng th·ªùi
- **Resource utilization**: T·ªëi ∆∞u h√≥a vi·ªác s·ª≠ d·ª•ng CPU v√† memory

## V·∫•n ƒê·ªÅ Race Conditions

Khi nhi·ªÅu threads c√πng truy c·∫≠p v√† thay ƒë·ªïi d·ªØ li·ªáu chung, c√≥ th·ªÉ x·∫£y ra race conditions:

```ruby
# ‚ùå Kh√¥ng an to√†n - Race condition
counter = 0

threads = 5.times.map do
  Thread.new do
    1000.times do
      counter += 1  # Kh√¥ng thread-safe!
    end
  end
end

threads.each(&:join)
puts counter  # K·∫øt qu·∫£ kh√¥ng ƒëo√°n tr∆∞·ªõc ƒë∆∞·ª£c, th∆∞·ªùng < 5000
```

**V·∫•n ƒë·ªÅ**: Ph√©p to√°n `counter += 1` kh√¥ng ph·∫£i l√† atomic. N√≥ bao g·ªìm 3 b∆∞·ªõc:
1. ƒê·ªçc gi√° tr·ªã hi·ªán t·∫°i
2. TƒÉng gi√° tr·ªã l√™n 1
3. Ghi l·∫°i gi√° tr·ªã m·ªõi

Khi nhi·ªÅu threads th·ª±c hi·ªán ƒë·ªìng th·ªùi, c√≥ th·ªÉ d·∫´n ƒë·∫øn m·∫•t d·ªØ li·ªáu.

## Ph·∫ßn 1: C∆° B·∫£n - L√†m Quen V·ªõi Mutex

### 1.1 B·∫£o V·ªá Shared Counter V·ªõi Mutex

Mutex (Mutual Exclusion) ƒë·∫£m b·∫£o ch·ªâ c√≥ m·ªôt thread ƒë∆∞·ª£c truy c·∫≠p critical section t·∫°i m·ªôt th·ªùi ƒëi·ªÉm:

```ruby
require 'thread'

def safe_counter_example
  mutex = Mutex.new
  counter = 0

  threads = 5.times.map do
    Thread.new do
      1000.times do
        mutex.synchronize do
          counter += 1  # Critical section ƒë∆∞·ª£c b·∫£o v·ªá
        end
      end
    end
  end

  threads.each(&:join)
  puts "K·∫øt qu·∫£ an to√†n: #{counter}"  # => 5000
end

safe_counter_example
```

**Gi·∫£i th√≠ch:**
- `Mutex.new`: T·∫°o m·ªôt mutex m·ªõi
- `mutex.synchronize`: Kh√≥a mutex, th·ª±c thi block, sau ƒë√≥ m·ªü kh√≥a
- Ch·ªâ m·ªôt thread c√≥ th·ªÉ v√†o critical section t·∫°i m·ªôt th·ªùi ƒëi·ªÉm

### 1.2 Manual Lock v√† Unlock

ƒê√¥i khi b·∫°n c·∫ßn ki·ªÉm so√°t chi ti·∫øt h∆°n vi·ªác kh√≥a/m·ªü kh√≥a:

```ruby
require 'thread'

class ManualLockExample
  def initialize
    @mutex = Mutex.new
    @data = []
  end

  def safe_update(value)
    @mutex.lock
    begin
      # Critical section
      puts "Thread #{Thread.current.object_id} ƒëang x·ª≠ l√Ω #{value}"
      @data << value
      sleep(0.01)  # Simulate work
    ensure
      @mutex.unlock  # Lu√¥n unlock trong ensure block
    end
  end

  def get_data
    @mutex.synchronize { @data.dup }
  end
end

# S·ª≠ d·ª•ng
example = ManualLockExample.new
threads = 5.times.map do |i|
  Thread.new { example.safe_update("data_#{i}") }
end

threads.each(&:join)
puts "D·ªØ li·ªáu cu·ªëi c√πng: #{example.get_data}"
```

**L∆∞u √Ω quan tr·ªçng:**
- Lu√¥n s·ª≠ d·ª•ng `ensure` ƒë·ªÉ ƒë·∫£m b·∫£o mutex ƒë∆∞·ª£c unlock
- Tr√°nh deadlock b·∫±ng c√°ch kh√¥ng gi·ªØ lock qu√° l√¢u

### 1.3 Mutex Per Resource Pattern

T·∫°o m·ªôt mutex cho m·ªói resource ƒë·ªÉ tr√°nh blocking kh√¥ng c·∫ßn thi·∫øt:

```ruby
require 'thread'

class BankAccount
  def initialize(balance)
    @balance = balance
    @mutex = Mutex.new  # M·ªói account c√≥ mutex ri√™ng
  end

  def deposit(amount)
    @mutex.synchronize do
      old_balance = @balance
      sleep(0.01)  # Simulate processing time
      @balance = old_balance + amount
      puts "G·ª≠i #{amount}, s·ªë d∆∞ m·ªõi: #{@balance}"
    end
  end

  def withdraw(amount)
    @mutex.synchronize do
      if @balance >= amount
        old_balance = @balance
        sleep(0.01)
        @balance = old_balance - amount
        puts "R√∫t #{amount}, s·ªë d∆∞ m·ªõi: #{@balance}"
        true
      else
        puts "Kh√¥ng ƒë·ªß s·ªë d∆∞ ƒë·ªÉ r√∫t #{amount}"
        false
      end
    end
  end

  def balance
    @mutex.synchronize { @balance }
  end
end

# Demo
account1 = BankAccount.new(1000)
account2 = BankAccount.new(500)

# C√°c threads c√≥ th·ªÉ l√†m vi·ªác v·ªõi different accounts song song
threads = []
threads << Thread.new { account1.deposit(100) }
threads << Thread.new { account2.deposit(200) }
threads << Thread.new { account1.withdraw(50) }
threads << Thread.new { account2.withdraw(300) }

threads.each(&:join)

puts "Account 1 balance: #{account1.balance}"
puts "Account 2 balance: #{account2.balance}"
```

### 1.4 Ch·ªù Threads Ho√†n Th√†nh V·ªõi Join

`Thread#join` ƒë·∫£m b·∫£o main thread ch·ªù c√°c worker threads ho√†n th√†nh:

```ruby
require 'thread'

def demonstrate_join
  mutex = Mutex.new
  results = []
  
  puts "B·∫Øt ƒë·∫ßu x·ª≠ l√Ω..."
  start_time = Time.now

  threads = 4.times.map do |i|
    Thread.new do
      # Simulate different processing times
      processing_time = rand(0.5..2.0)
      sleep(processing_time)
      
      result = "K·∫øt qu·∫£ t·ª´ thread #{i} (#{processing_time.round(2)}s)"
      
      mutex.synchronize do
        results << result
        puts "‚úì #{result}"
      end
    end
  end

  # Ch·ªù t·∫•t c·∫£ threads ho√†n th√†nh
  threads.each(&:join)
  
  end_time = Time.now
  puts "\nHo√†n th√†nh sau #{(end_time - start_time).round(2)}s"
  puts "T·ªïng c·ªông #{results.length} k·∫øt qu·∫£"
end

demonstrate_join
```

## Ph·∫ßn 2: Trung C·∫•p - K·ªπ Thu·∫≠t N√¢ng Cao

### 2.1 Thread-Safe Class Design

Thi·∫øt k·∫ø class thread-safe t·ª´ ƒë·∫ßu:

```ruby
require 'thread'

class ThreadSafeCounter
  def initialize(initial_value = 0)
    @count = initial_value
    @mutex = Mutex.new
  end

  def increment(amount = 1)
    @mutex.synchronize do
      old_value = @count
      sleep(0.001)  # Simulate work that could cause race condition
      @count = old_value + amount
    end
  end

  def decrement(amount = 1)
    @mutex.synchronize do
      old_value = @count
      sleep(0.001)
      @count = old_value - amount
    end
  end

  def value
    @mutex.synchronize { @count }
  end

  def reset(new_value = 0)
    @mutex.synchronize { @count = new_value }
  end

  # Atomic operations
  def increment_and_get(amount = 1)
    @mutex.synchronize do
      @count += amount
      @count
    end
  end

  def compare_and_set(expected, new_value)
    @mutex.synchronize do
      if @count == expected
        @count = new_value
        true
      else
        false
      end
    end
  end
end

# Demo
counter = ThreadSafeCounter.new(100)

# Test concurrent operations
threads = []
threads += 10.times.map { Thread.new { 100.times { counter.increment } } }
threads += 5.times.map { Thread.new { 50.times { counter.decrement } } }

threads.each(&:join)

puts "Final value: #{counter.value}"  # Should be 100 + 1000 - 250 = 850
```

### 2.2 Non-Blocking Lock V·ªõi try_lock

`Mutex#try_lock` cho ph√©p th·ª≠ kh√≥a m√† kh√¥ng block thread:

```ruby
require 'thread'

class NonBlockingProcessor
  def initialize
    @mutex = Mutex.new
    @processing = false
    @queue = []
  end

  def add_task(task)
    @mutex.synchronize { @queue << task }
  end

  def try_process
    if @mutex.try_lock
      begin
        return false if @processing || @queue.empty?
        
        @processing = true
        task = @queue.shift
        
        puts "#{Thread.current.object_id}: B·∫Øt ƒë·∫ßu x·ª≠ l√Ω #{task}"
        sleep(0.1)  # Simulate work
        puts "#{Thread.current.object_id}: Ho√†n th√†nh #{task}"
        
        true
      ensure
        @processing = false
        @mutex.unlock
      end
    else
      puts "#{Thread.current.object_id}: Kh√¥ng th·ªÉ l·∫•y lock, th·ª≠ l·∫°i sau"
      false
    end
  end

  def queue_size
    @mutex.synchronize { @queue.size }
  end
end

# Demo
processor = NonBlockingProcessor.new

# Add tasks
10.times { |i| processor.add_task("Task_#{i}") }

# Multiple threads try to process
threads = 5.times.map do
  Thread.new do
    10.times do
      success = processor.try_process
      sleep(0.05) unless success
    end
  end
end

threads.each(&:join)
puts "Remaining tasks: #{processor.queue_size}"
```

### 2.3 ConditionVariable - Coordination Between Threads

`ConditionVariable` gi√∫p threads ch·ªù ƒë·ª£i v√† th√¥ng b√°o cho nhau:

```ruby
require 'thread'

class ProducerConsumerQueue
  def initialize(max_size = 5)
    @queue = []
    @max_size = max_size
    @mutex = Mutex.new
    @not_empty = ConditionVariable.new
    @not_full = ConditionVariable.new
  end

  def produce(item)
    @mutex.synchronize do
      # Ch·ªù cho ƒë·∫øn khi queue kh√¥ng full
      while @queue.size >= @max_size
        puts "Producer ch·ªù - Queue full (#{@queue.size}/#{@max_size})"
        @not_full.wait(@mutex)
      end
      
      @queue << item
      puts "Produced: #{item} (Queue: #{@queue.size}/#{@max_size})"
      
      # Th√¥ng b√°o cho consumers
      @not_empty.signal
    end
  end

  def consume
    @mutex.synchronize do
      # Ch·ªù cho ƒë·∫øn khi queue kh√¥ng empty
      while @queue.empty?
        puts "Consumer ch·ªù - Queue empty"
        @not_empty.wait(@mutex)
      end
      
      item = @queue.shift
      puts "Consumed: #{item} (Queue: #{@queue.size}/#{@max_size})"
      
      # Th√¥ng b√°o cho producers
      @not_full.signal
      
      item
    end
  end

  def size
    @mutex.synchronize { @queue.size }
  end
end

# Demo
queue = ProducerConsumerQueue.new(3)

# Producer thread
producer = Thread.new do
  10.times do |i|
    queue.produce("Item_#{i}")
    sleep(0.1)
  end
end

# Consumer threads
consumers = 2.times.map do |i|
  Thread.new do
    5.times do
      item = queue.consume
      sleep(0.2)  # Simulate processing
    end
  end
end

producer.join
consumers.each(&:join)
```

### 2.4 Double-Checked Locking Pattern

T·ªëi ∆∞u h√≥a lazy initialization:

```ruby
require 'thread'

class ConfigurationManager
  @instance = nil
  @mutex = Mutex.new

  def self.instance
    # First check (kh√¥ng c·∫ßn lock)
    return @instance if @instance

    @mutex.synchronize do
      # Second check (v·ªõi lock)
      @instance ||= new
    end
  end

  def initialize
    puts "Kh·ªüi t·∫°o Configuration..."
    sleep(0.2)  # Simulate expensive initialization
    @config = load_configuration
  end

  private

  def load_configuration
    {
      database: {
        host: 'localhost',
        port: 5432,
        pool_size: 10
      },
      cache: {
        ttl: 3600,
        max_size: 1000
      },
      api: {
        timeout: 30,
        retries: 3
      }
    }
  end

  def config
    @config
  end
end

# Test concurrent access
threads = 10.times.map do |i|
  Thread.new do
    config = ConfigurationManager.instance
    puts "Thread #{i}: #{config.object_id}"
  end
end

threads.each(&:join)
```

## Ph·∫ßn 3: N√¢ng Cao - K·ªπ Thu·∫≠t Chuy√™n Nghi·ªáp

### 3.1 Monitor - Reentrant Mutex

Ruby's `Monitor` cho ph√©p c√πng m·ªôt thread lock nhi·ªÅu l·∫ßn:

```ruby
require 'monitor'

class ThreadSafeBank
  include MonitorMixin

  def initialize
    super()  # Initialize MonitorMixin
    @accounts = {}
  end

  def create_account(id, initial_balance)
    synchronize do
      @accounts[id] = initial_balance
      log_transaction("Created account #{id} with balance #{initial_balance}")
    end
  end

  def transfer(from_id, to_id, amount)
    synchronize do
      return false unless @accounts[from_id] && @accounts[to_id]
      return false if @accounts[from_id] < amount

      # Nested synchronization - Monitor cho ph√©p reentrant
      withdraw_internal(from_id, amount)
      deposit_internal(to_id, amount)
      
      log_transaction("Transferred #{amount} from #{from_id} to #{to_id}")
      true
    end
  end

  def get_balance(id)
    synchronize { @accounts[id] }
  end

  private

  def withdraw_internal(id, amount)
    synchronize do  # Reentrant lock
      @accounts[id] -= amount
    end
  end

  def deposit_internal(id, amount)
    synchronize do  # Reentrant lock
      @accounts[id] += amount
    end
  end

  def log_transaction(message)
    synchronize do  # Reentrant lock
      puts "[#{Time.now}] #{message}"
    end
  end
end

# Demo
bank = ThreadSafeBank.new
bank.create_account('A', 1000)
bank.create_account('B', 500)

threads = []
threads << Thread.new { bank.transfer('A', 'B', 100) }
threads << Thread.new { bank.transfer('B', 'A', 50) }
threads << Thread.new { puts "Balance A: #{bank.get_balance('A')}" }
threads << Thread.new { puts "Balance B: #{bank.get_balance('B')}" }

threads.each(&:join)
```

### 3.2 Deadlock Prevention

Tr√°nh deadlock b·∫±ng ordered locking:

```ruby
require 'thread'

class DeadlockSafeTransfer
  def initialize
    @accounts = {}
    @mutexes = {}
  end

  def create_account(id, balance)
    @accounts[id] = balance
    @mutexes[id] = Mutex.new
  end

  def transfer_safe(from_id, to_id, amount)
    # Lu√¥n lock theo th·ª© t·ª± object_id ƒë·ªÉ tr√°nh deadlock
    first_id, second_id = [from_id, to_id].sort
    first_mutex = @mutexes[first_id]
    second_mutex = @mutexes[second_id]

    first_mutex.synchronize do
      second_mutex.synchronize do
        if @accounts[from_id] >= amount
          @accounts[from_id] -= amount
          @accounts[to_id] += amount
          puts "Transferred #{amount} from #{from_id} to #{to_id}"
          true
        else
          puts "Insufficient funds in #{from_id}"
          false
        end
      end
    end
  end

  def transfer_with_timeout(from_id, to_id, amount, timeout = 1.0)
    first_id, second_id = [from_id, to_id].sort
    first_mutex = @mutexes[first_id]
    second_mutex = @mutexes[second_id]

    start_time = Time.now

    if first_mutex.try_lock
      begin
        # Try to get second lock with timeout
        while !second_mutex.try_lock
          if Time.now - start_time > timeout
            puts "Transfer timeout: #{from_id} -> #{to_id}"
            return false
          end
          sleep(0.001)
        end

        begin
          if @accounts[from_id] >= amount
            @accounts[from_id] -= amount
            @accounts[to_id] += amount
            puts "Transferred #{amount} from #{from_id} to #{to_id}"
            true
          else
            false
          end
        ensure
          second_mutex.unlock
        end
      ensure
        first_mutex.unlock
      end
    else
      puts "Could not acquire first lock: #{first_id}"
      false
    end
  end

  def balance(id)
    @mutexes[id].synchronize { @accounts[id] }
  end
end

# Demo
bank = DeadlockSafeTransfer.new
bank.create_account('A', 1000)
bank.create_account('B', 800)
bank.create_account('C', 600)

# Concurrent transfers that could cause deadlock with naive locking
threads = []
threads << Thread.new { bank.transfer_safe('A', 'B', 100) }
threads << Thread.new { bank.transfer_safe('B', 'A', 50) }
threads << Thread.new { bank.transfer_safe('B', 'C', 200) }
threads << Thread.new { bank.transfer_safe('C', 'A', 150) }

threads.each(&:join)

puts "Final balances:"
puts "A: #{bank.balance('A')}"
puts "B: #{bank.balance('B')}"
puts "C: #{bank.balance('C')}"
```

## Ph·∫ßn 4: Expert Level - K·ªπ Thu·∫≠t Chuy√™n Gia

### 4.1 Lock Striping - Sharded Mutex Pool

ƒê·ªÉ tƒÉng throughput, chia resource th√†nh nhi·ªÅu shard v·ªõi mutex ri√™ng:

```ruby
require 'zlib'

class ShardedHashMap
  SHARD_COUNT = 16

  def initialize
    @shards = Array.new(SHARD_COUNT) { {} }
    @mutexes = Array.new(SHARD_COUNT) { Mutex.new }
  end

  def put(key, value)
    idx = shard_index(key)
    @mutexes[idx].synchronize do
      @shards[idx][key] = value
    end
  end

  def get(key)
    idx = shard_index(key)
    @mutexes[idx].synchronize do
      @shards[idx][key]
    end
  end

  def delete(key)
    idx = shard_index(key)
    @mutexes[idx].synchronize do
      @shards[idx].delete(key)
    end
  end

  def size
    total = 0
    @mutexes.each_with_index do |mutex, idx|
      mutex.synchronize do
        total += @shards[idx].size
      end
    end
    total
  end

  # Atomic increment operation
  def increment(key, amount = 1)
    idx = shard_index(key)
    @mutexes[idx].synchronize do
      @shards[idx][key] = (@shards[idx][key] || 0) + amount
    end
  end

  def keys
    all_keys = []
    @mutexes.each_with_index do |mutex, idx|
      mutex.synchronize do
        all_keys.concat(@shards[idx].keys)
      end
    end
    all_keys
  end

  private

  def shard_index(key)
    Zlib.crc32(key.to_s) % SHARD_COUNT
  end
end

# Performance test
def benchmark_sharded_map
  map = ShardedHashMap.new
  
  puts "Testing concurrent writes..."
  start_time = Time.now
  
  threads = 8.times.map do |thread_id|
    Thread.new do
      1000.times do |i|
        key = "thread_#{thread_id}_item_#{i}"
        map.put(key, "value_#{i}")
      end
    end
  end
  
  threads.each(&:join)
  
  end_time = Time.now
  puts "Wrote 8000 items in #{(end_time - start_time).round(3)}s"
  puts "Final size: #{map.size}"
  
  # Test concurrent increments
  puts "\nTesting concurrent increments..."
  start_time = Time.now
  
  threads = 10.times.map do
    Thread.new do
      1000.times do |i|
        map.increment("counter_#{i % 100}")
      end
    end
  end
  
  threads.each(&:join)
  
  end_time = Time.now
  puts "Performed 10000 increments in #{(end_time - start_time).round(3)}s"
end

benchmark_sharded_map
```

### 4.2 Fair FIFO Mutex

ƒê·∫£m b·∫£o fairness b·∫±ng FIFO queue:

```ruby
require 'thread'

class FairMutex
  def initialize
    @queue = []
    @cv = ConditionVariable.new
    @lock = Mutex.new
    @owner = nil
  end

  def synchronize
    thread_id = Thread.current.object_id
    
    @lock.synchronize do
      # Add to queue
      @queue << thread_id
      
      # Wait until it's our turn
      while @queue.first != thread_id || @owner
        @cv.wait(@lock)
      end
      
      # We got the lock
      @owner = thread_id
    end

    begin
      yield
    ensure
      @lock.synchronize do
        @owner = nil
        @queue.shift
        @cv.broadcast  # Wake up all waiting threads
      end
    end
  end

  def queue_length
    @lock.synchronize { @queue.length }
  end
end

# Demo fairness
def demonstrate_fairness
  fair_mutex = FairMutex.new
  results = []
  results_mutex = Mutex.new
  
  threads = 10.times.map do |i|
    Thread.new do
      fair_mutex.synchronize do
        timestamp = Time.now.to_f
        thread_info = "Thread #{i} acquired lock at #{timestamp}"
        
        results_mutex.synchronize do
          results << { thread: i, time: timestamp }
        end
        
        puts thread_info
        sleep(0.1)  # Hold lock briefly
      end
    end
  end
  
  threads.each(&:join)
  
  # Verify FIFO order
  puts "\nVerifying FIFO order:"
  results.sort_by! { |r| r[:time] }
  results.each_with_index do |result, index|
    puts "Position #{index}: Thread #{result[:thread]}"
  end
end

demonstrate_fairness
```

### 4.3 Custom Reentrant Mutex

T·ª± implement reentrant mutex v·ªõi ownership tracking:

```ruby
require 'thread'

class CustomReentrantMutex
  def initialize
    @owner = nil
    @depth = 0
    @cv = ConditionVariable.new
    @lock = Mutex.new
  end

  def synchronize
    acquire
    begin
      yield
    ensure
      release
    end
  end

  def acquire
    current_thread = Thread.current
    
    @lock.synchronize do
      if @owner == current_thread
        # Same thread, just increment depth
        @depth += 1
      else
        # Different thread, wait until available
        while @owner
          @cv.wait(@lock)
        end
        @owner = current_thread
        @depth = 1
      end
    end
  end

  def release
    current_thread = Thread.current
    
    @lock.synchronize do
      raise "Not owner" unless @owner == current_thread
      
      @depth -= 1
      if @depth == 0
        @owner = nil
        @cv.signal
      end
    end
  end

  def owned_by_current_thread?
    @lock.synchronize { @owner == Thread.current }
  end

  def lock_depth
    @lock.synchronize { @owner == Thread.current ? @depth : 0 }
  end
end

# Demo reentrant behavior
class ReentrantExample
  def initialize
    @mutex = CustomReentrantMutex.new
    @value = 0
  end

  def method_a
    @mutex.synchronize do
      puts "Method A: depth = #{@mutex.lock_depth}"
      @value += 1
      method_b  # Nested call
    end
  end

  def method_b
    @mutex.synchronize do
      puts "Method B: depth = #{@mutex.lock_depth}"
      @value += 10
      method_c  # Another nested call
    end
  end

  def method_c
    @mutex.synchronize do
      puts "Method C: depth = #{@mutex.lock_depth}"
      @value += 100
    end
  end

  def value
    @mutex.synchronize { @value }
  end
end

example = ReentrantExample.new
example.method_a
puts "Final value: #{example.value}"  # Should be 111
```

### 4.4 Thread Pool With Work Stealing

Advanced pattern cho high-performance concurrent processing:

```ruby
require 'thread'

class WorkStealingThreadPool
  def initialize(size = 4)
    @size = size
    @queues = Array.new(size) { Queue.new }
    @workers = []
    @shutdown = false
    @mutex = Mutex.new
    
    start_workers
  end

  def submit(task)
    return if @shutdown
    
    # Find queue with least work
    min_queue = @queues.min_by(&:size)
    min_queue << task
  end

  def shutdown
    @mutex.synchronize do
      @shutdown = true
      @size.times { |i| @queues[i] << :shutdown }
    end
    
    @workers.each(&:join)
  end

  private

  def start_workers
    @workers = @size.times.map do |worker_id|
      Thread.new { worker_loop(worker_id) }
    end
  end

  def worker_loop(worker_id)
    my_queue = @queues[worker_id]
    
    loop do
      task = get_task(worker_id, my_queue)
      
      case task
      when :shutdown
        break
      when Proc
        begin
          task.call
        rescue => e
          puts "Error in worker #{worker_id}: #{e.message}"
        end
      end
    end
    
    puts "Worker #{worker_id} shutting down"
  end

  def get_task(worker_id, my_queue)
    # Try own queue first
    begin
      return my_queue.pop(true)  # Non-blocking
    rescue ThreadError
      # Queue empty, try work stealing
    end
    
    # Try stealing from other queues
    other_queues = @queues.each_with_index.reject { |_, i| i == worker_id }
    other_queues.each do |queue, _|
      begin
        return queue.pop(true)
      rescue ThreadError
        # This queue is also empty
      end
    end
    
    # All queues empty, block on own queue
    my_queue.pop
  end
end

# Demo
pool = WorkStealingThreadPool.new(4)

# Submit various tasks
20.times do |i|
  pool.submit(proc do
    puts "Processing task #{i} on thread #{Thread.current.object_id}"
    sleep(rand(0.1..0.5))  # Simulate work
    puts "Completed task #{i}"
  end)
end

sleep(3)  # Let tasks complete
pool.shutdown
```

## Best Practices v√† L∆∞u √ù

### 1. Tr√°nh Common Pitfalls

```ruby
# ‚ùå Tr√°nh: Nested locks c√≥ th·ªÉ g√¢y deadlock
def bad_nested_locks
  @lock1.synchronize do
    @lock2.synchronize do
      # Dangerous if another thread locks in reverse order
    end
  end
end

# ‚úÖ T·ªët: Ordered locking
def good_ordered_locks
  first, second = [@lock1, @lock2].sort_by(&:object_id)
  first.synchronize do
    second.synchronize do
      # Safe
    end
  end
end

# ‚ùå Tr√°nh: Gi·ªØ lock qu√° l√¢u
def bad_long_lock
  @mutex.synchronize do
    expensive_network_call  # Blocks other threads unnecessarily
  end
end

# ‚úÖ T·ªët: Minimize lock time
def good_short_lock
  data = expensive_network_call
  @mutex.synchronize do
    @shared_data = data  # Quick update
  end
end
```

### 2. Performance Tips

- **Lock granularity**: S·ª≠ d·ª•ng fine-grained locks khi c√≥ th·ªÉ
- **Lock-free algorithms**: C√¢n nh·∫Øc atomic operations
- **Thread pool**: T√°i s·ª≠ d·ª•ng threads thay v√¨ t·∫°o m·ªõi
- **Work stealing**: C√¢n b·∫±ng t·∫£i gi·ªØa c√°c threads

### 3. Debugging Concurrent Code

```ruby
class DebuggableMutex
  def initialize(name)
    @name = name
    @mutex = Mutex.new
    @owner = nil
    @acquired_at = nil
  end

  def synchronize
    puts "[#{Time.now}] #{Thread.current.object_id} waiting for #{@name}"
    
    @mutex.synchronize do
      @owner = Thread.current.object_id
      @acquired_at = Time.now
      puts "[#{@acquired_at}] #{@owner} acquired #{@name}"
      
      begin
        yield
      ensure
        duration = Time.now - @acquired_at
        puts "[#{Time.now}] #{@owner} released #{@name} (held for #{duration.round(3)}s)"
        @owner = nil
        @acquired_at = nil
      end
    end
  end
end
```

## K·∫øt Lu·∫≠n

Concurrency trong Ruby l√† m·ªôt ch·ªß ƒë·ªÅ ph·ª©c t·∫°p nh∆∞ng c·ª±c k·ª≥ quan tr·ªçng. T·ª´ nh·ªØng kh√°i ni·ªám c∆° b·∫£n v·ªÅ Mutex ƒë·∫øn c√°c k·ªπ thu·∫≠t n√¢ng cao nh∆∞ lock striping v√† fair mutexes, m·ªói technique ƒë·ªÅu c√≥ use case ri√™ng.

### Nh·ªØng ƒëi·ªÉm ch√≠nh c·∫ßn nh·ªõ:

1. **C∆° b·∫£n**: S·ª≠ d·ª•ng `Mutex#synchronize` ƒë·ªÉ b·∫£o v·ªá critical sections
2. **Trung c·∫•p**: `ConditionVariable` cho thread coordination, `try_lock` cho non-blocking
3. **N√¢ng cao**: `Monitor` cho reentrant locks, ordered locking ƒë·ªÉ tr√°nh deadlock
4. **Expert**: Lock striping cho performance, custom implementations cho special needs

### Khi n√†o s·ª≠ d·ª•ng g√¨:

- **Simple shared state**: `Mutex#synchronize`
- **Producer-consumer**: `ConditionVariable`
- **High contention**: Lock striping ho·∫∑c lock-free algorithms
- **Nested locking**: `Monitor` ho·∫∑c custom reentrant mutex
- **Fairness required**: Custom FIFO mutex

### L·ªùi khuy√™n cu·ªëi:

- B·∫Øt ƒë·∫ßu ƒë∆°n gi·∫£n v·ªõi `Mutex#synchronize`
- Profile tr∆∞·ªõc khi optimize
- Test thoroughly v·ªõi concurrent workloads
- Document thread safety assumptions
- Consider alternatives nh∆∞ Actor model (Celluloid) ho·∫∑c async programming

Concurrency kh√¥ng d·ªÖ, nh∆∞ng v·ªõi nh·ªØng k·ªπ thu·∫≠t n√†y, b·∫°n c√≥ th·ªÉ x√¢y d·ª±ng nh·ªØng ·ª©ng d·ª•ng Ruby hi·ªáu su·∫•t cao v√† thread-safe! üöÄ
