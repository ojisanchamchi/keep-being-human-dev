"use strict";(self.webpackChunkkeep_being_human_dev=self.webpackChunkkeep_being_human_dev||[]).push([[78184],{46614:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>i,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"ruby/directory_management/expert/parallel_lazy_directory_traversal","title":"parallel_lazy_directory_traversal","description":"\ud83c\udfce\ufe0f Lazy Parallel Directory Traversal","source":"@site/docs/ruby/directory_management/expert/parallel_lazy_directory_traversal.md","sourceDirName":"ruby/directory_management/expert","slug":"/ruby/directory_management/expert/parallel_lazy_directory_traversal","permalink":"/keep-being-human-dev/docs/ruby/directory_management/expert/parallel_lazy_directory_traversal","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ruby/directory_management/expert/parallel_lazy_directory_traversal.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"cross_platform_realtime_dir_watcher","permalink":"/keep-being-human-dev/docs/ruby/directory_management/expert/cross_platform_realtime_dir_watcher"},"next":{"title":"pattern_based_traversal_with_pathname","permalink":"/keep-being-human-dev/docs/ruby/directory_management/middle/pattern_based_traversal_with_pathname"}}');var n=t(23420),l=t(65404);const o={},s=void 0,i={},c=[{value:"\ud83c\udfce\ufe0f Lazy Parallel Directory Traversal",id:"\ufe0f-lazy-parallel-directory-traversal",level:2}];function d(e){const r={code:"code",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",...(0,l.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(r.h2,{id:"\ufe0f-lazy-parallel-directory-traversal",children:"\ud83c\udfce\ufe0f Lazy Parallel Directory Traversal"}),"\n",(0,n.jsxs)(r.p,{children:["When working with massive directory trees, loading all paths into memory can be prohibitive. By combining ",(0,n.jsx)(r.code,{children:"Dir.glob"})," with ",(0,n.jsx)(r.code,{children:"Enumerator::Lazy"})," and ",(0,n.jsx)(r.code,{children:"concurrent-ruby"}),", you can stream file paths and process them concurrently without blowing out RAM."]}),"\n",(0,n.jsxs)(r.ol,{children:["\n",(0,n.jsxs)(r.li,{children:["Use ",(0,n.jsx)(r.code,{children:"Dir.glob"})," and wrap it in a lazy enumerator."]}),"\n",(0,n.jsxs)(r.li,{children:["Create a ",(0,n.jsx)(r.code,{children:"Concurrent::ThreadPoolExecutor"})," to throttle parallel work."]}),"\n",(0,n.jsxs)(r.li,{children:["Dispatch each path as a lightweight ",(0,n.jsx)(r.code,{children:"Concurrent::Promise"})," and handle results as they complete."]}),"\n"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-ruby",children:'require \'concurrent-ruby\'\n\nlazy_paths = Dir.glob("/var/data/**/*").lazy\nexecutor   = Concurrent::ThreadPoolExecutor.new(\n  min_threads: 2,\n  max_threads: 8,\n  max_queue: 1000,\n  fallback_policy: :caller_runs\n)\n\n# Process only .log files in parallel\nlazy_paths\n  .select { |p| p.end_with?(".log") }\n  .each do |path|\n    Concurrent::Promise.execute(executor: executor) do\n      # heavy I/O or CPU-bound operation\n      size = File.size(path)\n      # e.g., archive or analyze\n      { path: path, bytes: size }\n    end.then do |result|\n      puts "Processed #{result[:path]} (#{result[:bytes]} bytes)"\n    end\n  end\n\n# Ensure all tasks finish\nexecutor.shutdown\nexecutor.wait_for_termination\n'})})]})}function u(e={}){const{wrapper:r}={...(0,l.R)(),...e.components};return r?(0,n.jsx)(r,{...e,children:(0,n.jsx)(d,{...e})}):d(e)}},65404:(e,r,t)=>{t.d(r,{R:()=>o,x:()=>s});var a=t(36672);const n={},l=a.createContext(n);function o(e){const r=a.useContext(l);return a.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function s(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:o(e.components),a.createElement(l.Provider,{value:r},e.children)}}}]);