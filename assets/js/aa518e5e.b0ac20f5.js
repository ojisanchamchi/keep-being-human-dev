"use strict";(self.webpackChunkkeep_being_human_dev=self.webpackChunkkeep_being_human_dev||[]).push([[65580],{65404:(e,i,n)=>{n.d(i,{R:()=>o,x:()=>a});var t=n(36672);const r={},s=t.createContext(r);function o(e){const i=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(s.Provider,{value:i},e.children)}},89805:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>o,metadata:()=>t,toc:()=>p});const t=JSON.parse('{"id":"nosql/redis/expert/redis_cluster_pipeline_optimization","title":"redis_cluster_pipeline_optimization","description":"\ud83d\ude80 Optimize Bulk Writes with Cluster Pipeline and Auto\u2011Retry","source":"@site/docs/nosql/redis/expert/redis_cluster_pipeline_optimization.md","sourceDirName":"nosql/redis/expert","slug":"/nosql/redis/expert/redis_cluster_pipeline_optimization","permalink":"/keep-being-human-dev/docs/nosql/redis/expert/redis_cluster_pipeline_optimization","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/nosql/redis/expert/redis_cluster_pipeline_optimization.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"redis_list_usage","permalink":"/keep-being-human-dev/docs/nosql/redis/beginner/redis_list_usage"},"next":{"title":"redis_lua_atomic_operations","permalink":"/keep-being-human-dev/docs/nosql/redis/expert/redis_lua_atomic_operations"}}');var r=n(23420),s=n(65404);const o={},a=void 0,l={},p=[{value:"\ud83d\ude80 Optimize Bulk Writes with Cluster Pipeline and Auto\u2011Retry",id:"-optimize-bulk-writes-with-cluster-pipeline-and-autoretry",level:2}];function d(e){const i={code:"code",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.h2,{id:"-optimize-bulk-writes-with-cluster-pipeline-and-autoretry",children:"\ud83d\ude80 Optimize Bulk Writes with Cluster Pipeline and Auto\u2011Retry"}),"\n",(0,r.jsxs)(i.p,{children:["When using Redis Cluster, commands span multiple hash slots and nodes. The ",(0,r.jsx)(i.code,{children:"redis-rb"})," client\u2019s pipelining in cluster mode doesn\u2019t automatically handle MOVED redirects. By wrapping your pipeline in retry logic and rescanning slot mappings, you can maximize throughput and resilience during topology changes."]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-ruby",children:'# Bulk write with resilient cluster pipeline\ndef cluster_bulk_write(pairs)\n  retries = 0\n  begin\n    $redis.cluster_async do |conn|\n      conn.pipelined do |pipeline|\n        pairs.each { |key, value| pipeline.set(key, value) }\n      end\n    end\n  rescue Redis::CommandError => e\n    raise unless e.message.start_with?("MOVED")\n    retries += 1\n    raise if retries > 3\n    $redis.cluster.reload_slots_cache!\n    retry\n  end\nend\n\n# Usage\ndata = Array.new(1_000) { |i| ["user:#{i}", {name: "User#{i}"}.to_json] }\ncluster_bulk_write(data)\n'})})]})}function u(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);