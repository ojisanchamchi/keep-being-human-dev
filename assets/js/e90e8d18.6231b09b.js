"use strict";(self.webpackChunkkeep_being_human_dev=self.webpackChunkkeep_being_human_dev||[]).push([[31227],{17513:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>r,toc:()=>p});const r=JSON.parse('{"id":"gems/ruby-openai/middle/handle_rate_limit_retries","title":"handle_rate_limit_retries","description":"\u23f1\ufe0f Implement Exponential Backoff for Rate Limits","source":"@site/docs/gems/ruby-openai/middle/handle_rate_limit_retries.md","sourceDirName":"gems/ruby-openai/middle","slug":"/gems/ruby-openai/middle/handle_rate_limit_retries","permalink":"/keep-being-human-dev/docs/gems/ruby-openai/middle/handle_rate_limit_retries","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/gems/ruby-openai/middle/handle_rate_limit_retries.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"high_throughput_rate_limited_requests","permalink":"/keep-being-human-dev/docs/gems/ruby-openai/expert/high_throughput_rate_limited_requests"},"next":{"title":"parallel_requests","permalink":"/keep-being-human-dev/docs/gems/ruby-openai/middle/parallel_requests"}}');var i=n(23420),s=n(65404);const a={},o=void 0,l={},p=[{value:"\u23f1\ufe0f Implement Exponential Backoff for Rate Limits",id:"\ufe0f-implement-exponential-backoff-for-rate-limits",level:2}];function c(e){const t={code:"code",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h2,{id:"\ufe0f-implement-exponential-backoff-for-rate-limits",children:"\u23f1\ufe0f Implement Exponential Backoff for Rate Limits"}),"\n",(0,i.jsxs)(t.p,{children:["API calls can exceed rate limits or fail transiently. Wrap your requests in retry logic with exponential backoff to handle 429 or 5xx errors gracefully. Use Ruby\u2019s ",(0,i.jsx)(t.code,{children:"retry"})," and ",(0,i.jsx)(t.code,{children:"sleep"})," to pause before repeating."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-ruby",children:'require "ruby/openai"\n\nclient = OpenAI::Client.new\n\ndef resilient_completion(client, params, max_retries: 5)\n  attempts = 0\n  begin\n    client.chat.completions(parameters: params)\n  rescue OpenAI::Error => e\n    if [429, 500, 502, 503, 504].include?(e.http_status) && attempts < max_retries\n      attempts += 1\n      sleep(2**attempts) # exponential backoff\n      retry\n    else\n      raise\n    end\n  end\nend\n\nresponse = resilient_completion(client, {\n  model: "gpt-3.5-turbo",\n  messages: [{ role: "user", content: "Help me with retries." }]\n})\nputs response.dig("choices", 0, "message", "content")\n'})}),"\n",(0,i.jsx)(t.p,{children:"This pattern ensures robust handling of temporary errors and avoids overwhelming the API."})]})}function m(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},65404:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>o});var r=n(36672);const i={},s=r.createContext(i);function a(e){const t=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(s.Provider,{value:t},e.children)}}}]);