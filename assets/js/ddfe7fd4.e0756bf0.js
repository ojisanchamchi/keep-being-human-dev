"use strict";(self.webpackChunkkeep_being_human_dev=self.webpackChunkkeep_being_human_dev||[]).push([[35223],{44530:n=>{n.exports=JSON.parse('{"permalink":"/keep-being-human-dev/blog/ruby-compression-tu-co-ban-den-nang-cao","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/ruby-compression-tu-co-ban-den-nang-cao.md","source":"@site/blog/ruby-compression-tu-co-ban-den-nang-cao.md","title":"Ruby Compression: T\u1eeb C\u01a1 B\u1ea3n \u0110\u1ebfn N\xe2ng Cao - H\u01b0\u1edbng D\u1eabn To\xe0n Di\u1ec7n","description":"Compression (n\xe9n d\u1eef li\u1ec7u) l\xe0 m\u1ed9t k\u1ef9 thu\u1eadt quan tr\u1ecdng trong l\u1eadp tr\xecnh, gi\xfap gi\u1ea3m k\xedch th\u01b0\u1edbc file, ti\u1ebft ki\u1ec7m b\u0103ng th\xf4ng v\xe0 t\u0103ng hi\u1ec7u su\u1ea5t \u1ee9ng d\u1ee5ng. Trong b\xe0i vi\u1ebft n\xe0y, ch\xfang ta s\u1ebd kh\xe1m ph\xe1 c\xe1c k\u1ef9 thu\u1eadt compression trong Ruby t\u1eeb c\u01a1 b\u1ea3n \u0111\u1ebfn n\xe2ng cao, v\u1edbi c\xe1c v\xed d\u1ee5 th\u1ef1c t\u1ebf v\xe0 best practices.","date":"2025-07-24T10:20:47.000Z","tags":[{"inline":false,"label":"Ruby","permalink":"/keep-being-human-dev/blog/tags/ruby","description":"Content related to Ruby programming language"},{"inline":false,"label":"Compression","permalink":"/keep-being-human-dev/blog/tags/compression","description":"Content about data compression techniques and algorithms"},{"inline":false,"label":"Gzip","permalink":"/keep-being-human-dev/blog/tags/gzip","description":"Content related to Gzip compression format and usage"},{"inline":false,"label":"ZIP","permalink":"/keep-being-human-dev/blog/tags/zip","description":"Content about ZIP archive format and operations"},{"inline":false,"label":"Performance","permalink":"/keep-being-human-dev/blog/tags/performance","description":"Content related to performance optimization and techniques"},{"inline":false,"label":"Optimization","permalink":"/keep-being-human-dev/blog/tags/optimization","description":"Content about code and performance optimization techniques"},{"inline":false,"label":"Zlib","permalink":"/keep-being-human-dev/blog/tags/zlib","description":"Content related to Zlib compression library"},{"inline":false,"label":"Streaming","permalink":"/keep-being-human-dev/blog/tags/streaming","description":"Content about streaming data processing and techniques"}],"readingTime":8.61,"hasTruncateMarker":true,"authors":[{"name":"Dang Quang Minh","title":"Nh\xe2n vi\xean o\xe1nh m\xe1y t\xednh","url":"https://github.com/ojisanchamchi","page":{"permalink":"/keep-being-human-dev/blog/authors/admin"},"socials":{"github":"https://github.com/ojisanchamchi"},"imageURL":"https://github.com/ojisanchamchi.png","key":"admin"}],"frontMatter":{"slug":"ruby-compression-tu-co-ban-den-nang-cao","title":"Ruby Compression: T\u1eeb C\u01a1 B\u1ea3n \u0110\u1ebfn N\xe2ng Cao - H\u01b0\u1edbng D\u1eabn To\xe0n Di\u1ec7n","authors":["admin"],"tags":["ruby","compression","gzip","zip","performance","optimization","zlib","streaming"]},"unlisted":false,"nextItem":{"title":"Ruby Concurrency & Mutexes: T\u1eeb C\u01a1 B\u1ea3n \u0110\u1ebfn N\xe2ng Cao - H\u01b0\u1edbng D\u1eabn To\xe0n Di\u1ec7n","permalink":"/keep-being-human-dev/blog/ruby-concurrency-mutexes-tu-co-ban-den-nang-cao"}}')},63053:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>t,toc:()=>c});var t=i(44530),s=i(23420),r=i(65404);const l={slug:"ruby-compression-tu-co-ban-den-nang-cao",title:"Ruby Compression: T\u1eeb C\u01a1 B\u1ea3n \u0110\u1ebfn N\xe2ng Cao - H\u01b0\u1edbng D\u1eabn To\xe0n Di\u1ec7n",authors:["admin"],tags:["ruby","compression","gzip","zip","performance","optimization","zlib","streaming"]},o="Ruby Compression: T\u1eeb C\u01a1 B\u1ea3n \u0110\u1ebfn N\xe2ng Cao",a={authorsImageUrls:[void 0]},c=[{value:"T\u1ea1i Sao C\u1ea7n Compression?",id:"t\u1ea1i-sao-c\u1ea7n-compression",level:2},{value:"Ph\u1ea7n 1: C\u01a1 B\u1ea3n - L\xe0m Quen V\u1edbi Compression",id:"ph\u1ea7n-1-c\u01a1-b\u1ea3n---l\xe0m-quen-v\u1edbi-compression",level:2},{value:"1.1 N\xe9n File V\u1edbi Gzip",id:"11-n\xe9n-file-v\u1edbi-gzip",level:3},{value:"1.2 T\u1ea1o ZIP Archive",id:"12-t\u1ea1o-zip-archive",level:3},{value:"Ph\u1ea7n 2: Trung C\u1ea5p - K\u1ef9 Thu\u1eadt N\xe2ng Cao",id:"ph\u1ea7n-2-trung-c\u1ea5p---k\u1ef9-thu\u1eadt-n\xe2ng-cao",level:2},{value:"2.1 N\xe9n String Trong Memory",id:"21-n\xe9n-string-trong-memory",level:3},{value:"2.2 N\xe9n v\xe0 Gi\u1ea3i N\xe9n File Streaming",id:"22-n\xe9n-v\xe0-gi\u1ea3i-n\xe9n-file-streaming",level:3},{value:"Ph\u1ea7n 3: N\xe2ng Cao - K\u1ef9 Thu\u1eadt Chuy\xean Nghi\u1ec7p",id:"ph\u1ea7n-3-n\xe2ng-cao---k\u1ef9-thu\u1eadt-chuy\xean-nghi\u1ec7p",level:2},{value:"3.1 T\u1ea1o TAR.GZ Archives",id:"31-t\u1ea1o-targz-archives",level:3},{value:"3.2 Streaming Large File Compression",id:"32-streaming-large-file-compression",level:3},{value:"Ph\u1ea7n 4: Expert Level - K\u1ef9 Thu\u1eadt Chuy\xean Gia",id:"ph\u1ea7n-4-expert-level---k\u1ef9-thu\u1eadt-chuy\xean-gia",level:2},{value:"4.1 Custom Streaming Chunked Compression",id:"41-custom-streaming-chunked-compression",level:3},{value:"4.2 Multi-threaded Compression",id:"42-multi-threaded-compression",level:3},{value:"Best Practices v\xe0 L\u01b0u \xdd",id:"best-practices-v\xe0-l\u01b0u-\xfd",level:2},{value:"1. Ch\u1ecdn M\u1ee9c \u0110\u1ed9 N\xe9n Ph\xf9 H\u1ee3p",id:"1-ch\u1ecdn-m\u1ee9c-\u0111\u1ed9-n\xe9n-ph\xf9-h\u1ee3p",level:3},{value:"2. Memory Management",id:"2-memory-management",level:3},{value:"3. Error Handling",id:"3-error-handling",level:3},{value:"4. Performance Tips",id:"4-performance-tips",level:3},{value:"K\u1ebft Lu\u1eadn",id:"k\u1ebft-lu\u1eadn",level:2}];function p(n){const e={code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.p,{children:"Compression (n\xe9n d\u1eef li\u1ec7u) l\xe0 m\u1ed9t k\u1ef9 thu\u1eadt quan tr\u1ecdng trong l\u1eadp tr\xecnh, gi\xfap gi\u1ea3m k\xedch th\u01b0\u1edbc file, ti\u1ebft ki\u1ec7m b\u0103ng th\xf4ng v\xe0 t\u0103ng hi\u1ec7u su\u1ea5t \u1ee9ng d\u1ee5ng. Trong b\xe0i vi\u1ebft n\xe0y, ch\xfang ta s\u1ebd kh\xe1m ph\xe1 c\xe1c k\u1ef9 thu\u1eadt compression trong Ruby t\u1eeb c\u01a1 b\u1ea3n \u0111\u1ebfn n\xe2ng cao, v\u1edbi c\xe1c v\xed d\u1ee5 th\u1ef1c t\u1ebf v\xe0 best practices."}),"\n",(0,s.jsx)(e.h2,{id:"t\u1ea1i-sao-c\u1ea7n-compression",children:"T\u1ea1i Sao C\u1ea7n Compression?"}),"\n",(0,s.jsx)(e.p,{children:"Tr\u01b0\u1edbc khi \u0111i v\xe0o chi ti\u1ebft, h\xe3y hi\u1ec3u t\u1ea1i sao compression l\u1ea1i quan tr\u1ecdng:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Ti\u1ebft ki\u1ec7m dung l\u01b0\u1ee3ng l\u01b0u tr\u1eef"}),": Gi\u1ea3m k\xedch th\u01b0\u1edbc file tr\xean disk"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"T\u0103ng t\u1ed1c \u0111\u1ed9 truy\u1ec1n t\u1ea3i"}),": Gi\u1ea3m th\u1eddi gian upload/download"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Gi\u1ea3m b\u0103ng th\xf4ng"}),": Ti\u1ebft ki\u1ec7m chi ph\xed network"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"C\u1ea3i thi\u1ec7n performance"}),": Faster I/O operations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Backup hi\u1ec7u qu\u1ea3"}),": N\xe9n d\u1eef li\u1ec7u backup"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"ph\u1ea7n-1-c\u01a1-b\u1ea3n---l\xe0m-quen-v\u1edbi-compression",children:"Ph\u1ea7n 1: C\u01a1 B\u1ea3n - L\xe0m Quen V\u1edbi Compression"}),"\n",(0,s.jsx)(e.h3,{id:"11-n\xe9n-file-v\u1edbi-gzip",children:"1.1 N\xe9n File V\u1edbi Gzip"}),"\n",(0,s.jsxs)(e.p,{children:["Ruby cung c\u1ea5p th\u01b0 vi\u1ec7n ",(0,s.jsx)(e.code,{children:"Zlib"})," built-in \u0111\u1ec3 l\xe0m vi\u1ec7c v\u1edbi compression. \u0110\xe2y l\xe0 c\xe1ch \u0111\u01a1n gi\u1ea3n nh\u1ea5t \u0111\u1ec3 n\xe9n m\u1ed9t file:"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:"require 'zlib'\n\ndef compress_file_with_gzip(source, destination)\n  Zlib::GzipWriter.open(destination) do |gz|\n    File.open(source, 'rb') do |file|\n      while chunk = file.read(16 * 1024) # \u0110\u1ecdc t\u1eebng chunk 16KB\n        gz.write(chunk)\n      end\n    end\n  end\n  \n  puts \"\u0110\xe3 n\xe9n #{source} th\xe0nh #{destination}\"\nend\n\n# S\u1eed d\u1ee5ng\ncompress_file_with_gzip('example.txt', 'example.txt.gz')\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Gi\u1ea3i th\xedch:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"Zlib::GzipWriter.open"}),": M\u1edf file \u0111\u1ec3 ghi d\u1eef li\u1ec7u \u0111\xe3 n\xe9n"]}),"\n",(0,s.jsx)(e.li,{children:"\u0110\u1ecdc file theo chunk \u0111\u1ec3 tr\xe1nh load to\xe0n b\u1ed9 v\xe0o memory"}),"\n",(0,s.jsx)(e.li,{children:"Block t\u1ef1 \u0111\u1ed9ng \u0111\xf3ng file khi ho\xe0n th\xe0nh"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"12-t\u1ea1o-zip-archive",children:"1.2 T\u1ea1o ZIP Archive"}),"\n",(0,s.jsxs)(e.p,{children:["\u0110\u1ec3 t\u1ea1o file ZIP ch\u1ee9a nhi\u1ec1u file, ch\xfang ta s\u1eed d\u1ee5ng gem ",(0,s.jsx)(e.code,{children:"rubyzip"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"gem install rubyzip\n"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:"require 'zip'\n\ndef create_zip_archive(files_to_zip, output_zip)\n  Zip::File.open(output_zip, Zip::File::CREATE) do |zipfile|\n    files_to_zip.each do |filename|\n      # Ki\u1ec3m tra file t\u1ed3n t\u1ea1i\n      if File.exist?(filename)\n        zipfile.add(File.basename(filename), filename)\n        puts \"\u0110\xe3 th\xeam #{filename} v\xe0o archive\"\n      else\n        puts \"C\u1ea3nh b\xe1o: File #{filename} kh\xf4ng t\u1ed3n t\u1ea1i\"\n      end\n    end\n  end\nend\n\n# S\u1eed d\u1ee5ng\nfiles = ['file1.txt', 'file2.txt', 'data.json']\ncreate_zip_archive(files, 'archive.zip')\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"L\u01b0u \xfd quan tr\u1ecdng:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Lu\xf4n ki\u1ec3m tra file t\u1ed3n t\u1ea1i tr\u01b0\u1edbc khi th\xeam v\xe0o ZIP"}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"File.basename()"})," ch\u1ec9 l\u1ea5y t\xean file, kh\xf4ng bao g\u1ed3m \u0111\u01b0\u1eddng d\u1eabn"]}),"\n",(0,s.jsx)(e.li,{children:"S\u1eed d\u1ee5ng block \u0111\u1ec3 t\u1ef1 \u0111\u1ed9ng \u0111\xf3ng ZIP file"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"ph\u1ea7n-2-trung-c\u1ea5p---k\u1ef9-thu\u1eadt-n\xe2ng-cao",children:"Ph\u1ea7n 2: Trung C\u1ea5p - K\u1ef9 Thu\u1eadt N\xe2ng Cao"}),"\n",(0,s.jsx)(e.h3,{id:"21-n\xe9n-string-trong-memory",children:"2.1 N\xe9n String Trong Memory"}),"\n",(0,s.jsx)(e.p,{children:"\u0110\u1ed1i v\u1edbi d\u1eef li\u1ec7u t\u1ea1m th\u1eddi nh\u01b0 JSON payload ho\u1eb7c cache, n\xe9n trong memory s\u1ebd nhanh h\u01a1n:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:'require \'zlib\'\n\ndef compress_string_in_memory(data, level: Zlib::BEST_COMPRESSION)\n  # N\xe9n d\u1eef li\u1ec7u\n  compressed = Zlib::Deflate.deflate(data, level)\n  \n  puts "K\xedch th\u01b0\u1edbc g\u1ed1c: #{data.bytesize} bytes"\n  puts "K\xedch th\u01b0\u1edbc sau n\xe9n: #{compressed.bytesize} bytes"\n  puts "T\u1ef7 l\u1ec7 n\xe9n: #{((1 - compressed.bytesize.to_f / data.bytesize) * 100).round(2)}%"\n  \n  compressed\nend\n\ndef decompress_string(compressed_data)\n  Zlib::Inflate.inflate(compressed_data)\nend\n\n# V\xed d\u1ee5 v\u1edbi JSON data\njson_data = {\n  users: (1..1000).map { |i| \n    { id: i, name: "User #{i}", email: "user#{i}@example.com" }\n  }\n}.to_json\n\ncompressed = compress_string_in_memory(json_data)\ndecompressed = decompress_string(compressed)\n\nputs "D\u1eef li\u1ec7u kh\xf4i ph\u1ee5c ch\xednh x\xe1c: #{decompressed == json_data}"\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"C\xe1c m\u1ee9c \u0111\u1ed9 n\xe9n:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"Zlib::NO_COMPRESSION"}),": Kh\xf4ng n\xe9n (0)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"Zlib::BEST_SPEED"}),": N\xe9n nhanh nh\u1ea5t (1)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"Zlib::DEFAULT_COMPRESSION"}),": C\xe2n b\u1eb1ng (6)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"Zlib::BEST_COMPRESSION"}),": N\xe9n t\u1ed1t nh\u1ea5t (9)"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"22-n\xe9n-v\xe0-gi\u1ea3i-n\xe9n-file-streaming",children:"2.2 N\xe9n v\xe0 Gi\u1ea3i N\xe9n File Streaming"}),"\n",(0,s.jsx)(e.p,{children:"Ph\u01b0\u01a1ng ph\xe1p streaming gi\xfap x\u1eed l\xfd file l\u1edbn m\xe0 kh\xf4ng c\u1ea7n load to\xe0n b\u1ed9 v\xe0o memory:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:"require 'zlib'\n\nclass FileCompressor\n  CHUNK_SIZE = 16 * 1024 # 16KB chunks\n  \n  def self.compress_file(input_path, output_path)\n    File.open(input_path, 'rb') do |input|\n      Zlib::GzipWriter.open(output_path) do |gz|\n        while chunk = input.read(CHUNK_SIZE)\n          gz.write(chunk)\n        end\n      end\n    end\n    \n    original_size = File.size(input_path)\n    compressed_size = File.size(output_path)\n    compression_ratio = ((1 - compressed_size.to_f / original_size) * 100).round(2)\n    \n    puts \"N\xe9n ho\xe0n th\xe0nh:\"\n    puts \"  File g\u1ed1c: #{format_bytes(original_size)}\"\n    puts \"  File n\xe9n: #{format_bytes(compressed_size)}\"\n    puts \"  T\u1ef7 l\u1ec7 n\xe9n: #{compression_ratio}%\"\n  end\n  \n  def self.decompress_file(input_path, output_path)\n    Zlib::GzipReader.open(input_path) do |gz|\n      File.open(output_path, 'wb') do |output|\n        while chunk = gz.read(CHUNK_SIZE)\n          output.write(chunk)\n        end\n      end\n    end\n    \n    puts \"Gi\u1ea3i n\xe9n ho\xe0n th\xe0nh: #{output_path}\"\n  end\n  \n  private\n  \n  def self.format_bytes(bytes)\n    units = ['B', 'KB', 'MB', 'GB']\n    size = bytes.to_f\n    unit_index = 0\n    \n    while size >= 1024 && unit_index < units.length - 1\n      size /= 1024\n      unit_index += 1\n    end\n    \n    \"#{size.round(2)} #{units[unit_index]}\"\n  end\nend\n\n# S\u1eed d\u1ee5ng\nFileCompressor.compress_file('large_file.log', 'large_file.log.gz')\nFileCompressor.decompress_file('large_file.log.gz', 'restored_file.log')\n"})}),"\n",(0,s.jsx)(e.h2,{id:"ph\u1ea7n-3-n\xe2ng-cao---k\u1ef9-thu\u1eadt-chuy\xean-nghi\u1ec7p",children:"Ph\u1ea7n 3: N\xe2ng Cao - K\u1ef9 Thu\u1eadt Chuy\xean Nghi\u1ec7p"}),"\n",(0,s.jsx)(e.h3,{id:"31-t\u1ea1o-targz-archives",children:"3.1 T\u1ea1o TAR.GZ Archives"}),"\n",(0,s.jsxs)(e.p,{children:["\u0110\u1ec3 t\u1ea1o archive v\u1edbi metadata v\xe0 permissions, k\u1ebft h\u1ee3p ",(0,s.jsx)(e.code,{children:"Archive::Tar::Minitar"})," v\u1edbi ",(0,s.jsx)(e.code,{children:"Zlib"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"gem install minitar\n"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:"require 'zlib'\nrequire 'archive/tar/minitar'\ninclude Archive::Tar\n\nclass TarGzArchiver\n  def self.create_archive(sources, output_path, compression_level: Zlib::BEST_COMPRESSION)\n    Zlib::GzipWriter.open(output_path, compression_level) do |gzip|\n      Minitar::Writer.open(gzip) do |tar|\n        sources.each do |path|\n          if File.directory?(path)\n            puts \"Th\xeam th\u01b0 m\u1ee5c: #{path}\"\n            Minitar.pack_dir(path, tar)\n          elsif File.file?(path)\n            puts \"Th\xeam file: #{path}\"\n            Minitar.pack_file(path, tar)\n          else\n            puts \"C\u1ea3nh b\xe1o: #{path} kh\xf4ng t\u1ed3n t\u1ea1i\"\n          end\n        end\n      end\n    end\n    \n    puts \"T\u1ea1o archive th\xe0nh c\xf4ng: #{output_path}\"\n  end\n  \n  def self.extract_archive(archive_path, destination_dir)\n    Dir.mkdir(destination_dir) unless Dir.exist?(destination_dir)\n    \n    Zlib::GzipReader.open(archive_path) do |gzip|\n      Minitar::Reader.open(gzip) do |tar|\n        tar.each do |entry|\n          destination_path = File.join(destination_dir, entry.full_name)\n          \n          if entry.directory?\n            Dir.mkdir(destination_path) unless Dir.exist?(destination_path)\n          else\n            File.open(destination_path, 'wb') do |file|\n              file.write(entry.read)\n            end\n            # Kh\xf4i ph\u1ee5c permissions\n            File.chmod(entry.mode, destination_path)\n          end\n          \n          puts \"Gi\u1ea3i n\xe9n: #{entry.full_name}\"\n        end\n      end\n    end\n    \n    puts \"Gi\u1ea3i n\xe9n ho\xe0n th\xe0nh v\xe0o: #{destination_dir}\"\n  end\nend\n\n# S\u1eed d\u1ee5ng\nsources = ['app/', 'config/', 'README.md']\nTarGzArchiver.create_archive(sources, 'backup.tar.gz')\nTarGzArchiver.extract_archive('backup.tar.gz', 'restored/')\n"})}),"\n",(0,s.jsx)(e.h3,{id:"32-streaming-large-file-compression",children:"3.2 Streaming Large File Compression"}),"\n",(0,s.jsx)(e.p,{children:"\u0110\u1ed1i v\u1edbi file r\u1ea5t l\u1edbn, c\u1ea7n t\u1ed1i \u01b0u h\xf3a memory usage v\xe0 performance:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:"require 'zlib'\n\nclass LargeFileCompressor\n  DEFAULT_BUFFER_SIZE = 64 * 1024 # 64KB buffer\n  \n  def initialize(buffer_size: DEFAULT_BUFFER_SIZE)\n    @buffer_size = buffer_size\n  end\n  \n  def compress_large_file(input_path, output_path, level: Zlib::BEST_SPEED)\n    start_time = Time.now\n    bytes_processed = 0\n    \n    File.open(input_path, 'rb') do |input|\n      Zlib::GzipWriter.open(output_path, level) do |gz|\n        while chunk = input.read(@buffer_size)\n          gz.write(chunk)\n          bytes_processed += chunk.bytesize\n          \n          # Progress reporting\n          if bytes_processed % (1024 * 1024) == 0 # M\u1ed7i 1MB\n            print \"\\r\u0110\xe3 x\u1eed l\xfd: #{format_bytes(bytes_processed)}\"\n          end\n        end\n      end\n    end\n    \n    end_time = Time.now\n    processing_time = end_time - start_time\n    \n    original_size = File.size(input_path)\n    compressed_size = File.size(output_path)\n    \n    puts \"\\n\\nTh\u1ed1ng k\xea n\xe9n:\"\n    puts \"  Th\u1eddi gian x\u1eed l\xfd: #{processing_time.round(2)}s\"\n    puts \"  T\u1ed1c \u0111\u1ed9: #{format_bytes(original_size / processing_time)}/s\"\n    puts \"  K\xedch th\u01b0\u1edbc g\u1ed1c: #{format_bytes(original_size)}\"\n    puts \"  K\xedch th\u01b0\u1edbc n\xe9n: #{format_bytes(compressed_size)}\"\n    puts \"  T\u1ef7 l\u1ec7 n\xe9n: #{((1 - compressed_size.to_f / original_size) * 100).round(2)}%\"\n  end\n  \n  private\n  \n  def format_bytes(bytes)\n    units = ['B', 'KB', 'MB', 'GB', 'TB']\n    size = bytes.to_f\n    unit_index = 0\n    \n    while size >= 1024 && unit_index < units.length - 1\n      size /= 1024\n      unit_index += 1\n    end\n    \n    \"#{size.round(2)} #{units[unit_index]}\"\n  end\nend\n\n# S\u1eed d\u1ee5ng\ncompressor = LargeFileCompressor.new(buffer_size: 128 * 1024) # 128KB buffer\ncompressor.compress_large_file('huge_video.mp4', 'huge_video.mp4.gz')\n"})}),"\n",(0,s.jsx)(e.h2,{id:"ph\u1ea7n-4-expert-level---k\u1ef9-thu\u1eadt-chuy\xean-gia",children:"Ph\u1ea7n 4: Expert Level - K\u1ef9 Thu\u1eadt Chuy\xean Gia"}),"\n",(0,s.jsx)(e.h3,{id:"41-custom-streaming-chunked-compression",children:"4.1 Custom Streaming Chunked Compression"}),"\n",(0,s.jsx)(e.p,{children:"\u0110\xe2y l\xe0 k\u1ef9 thu\u1eadt n\xe2ng cao nh\u1ea5t, cho ph\xe9p ki\u1ec3m so\xe1t ho\xe0n to\xe0n qu\xe1 tr\xecnh compression:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:'require \'zlib\'\n\nclass AdvancedStreamCompressor\n  CHUNK_SIZE = 16 * 1024 # 16KB per chunk\n  \n  def self.compress_with_metadata(input_path, output_path, level: Zlib::BEST_COMPRESSION)\n    File.open(input_path, \'rb\') do |infile|\n      File.open(output_path, \'wb\') do |outfile|\n        gz = Zlib::GzipWriter.new(outfile, level)\n        \n        # T\xf9y ch\u1ec9nh Gzip header v\u1edbi metadata\n        gz.orig_name = File.basename(input_path)\n        gz.mtime = File.mtime(input_path).to_i\n        gz.comment = "Compressed by Ruby Advanced Compressor"\n        \n        # Streaming compression v\u1edbi progress tracking\n        total_size = File.size(input_path)\n        processed = 0\n        \n        while chunk = infile.read(CHUNK_SIZE)\n          gz.write(chunk)\n          processed += chunk.bytesize\n          \n          # Progress bar\n          progress = (processed.to_f / total_size * 100).round(1)\n          print "\\rProgress: #{progress}% [#{format_progress_bar(progress)}]"\n        end\n        \n        gz.close\n        puts "\\nHo\xe0n th\xe0nh!"\n      end\n    end\n  end\n  \n  def self.benchmark_compression_levels(input_path)\n    puts "Benchmark c\xe1c m\u1ee9c \u0111\u1ed9 n\xe9n cho file: #{File.basename(input_path)}"\n    puts "=" * 60\n    \n    levels = [\n      [Zlib::BEST_SPEED, "BEST_SPEED"],\n      [Zlib::DEFAULT_COMPRESSION, "DEFAULT"],\n      [Zlib::BEST_COMPRESSION, "BEST_COMPRESSION"]\n    ]\n    \n    original_size = File.size(input_path)\n    \n    levels.each do |level, name|\n      output_path = "#{input_path}.#{name.downcase}.gz"\n      \n      start_time = Time.now\n      compress_with_metadata(input_path, output_path, level: level)\n      end_time = Time.now\n      \n      compressed_size = File.size(output_path)\n      compression_ratio = ((1 - compressed_size.to_f / original_size) * 100).round(2)\n      processing_time = (end_time - start_time).round(2)\n      \n      puts "\\n#{name}:"\n      puts "  Th\u1eddi gian: #{processing_time}s"\n      puts "  K\xedch th\u01b0\u1edbc: #{format_bytes(compressed_size)}"\n      puts "  T\u1ef7 l\u1ec7 n\xe9n: #{compression_ratio}%"\n      puts "  T\u1ed1c \u0111\u1ed9: #{format_bytes(original_size / processing_time)}/s"\n      puts\n      \n      # Cleanup\n      File.delete(output_path)\n    end\n  end\n  \n  private\n  \n  def self.format_progress_bar(progress, width: 30)\n    filled = (progress / 100.0 * width).round\n    empty = width - filled\n    "\u2588" * filled + "\u2591" * empty\n  end\n  \n  def self.format_bytes(bytes)\n    units = [\'B\', \'KB\', \'MB\', \'GB\', \'TB\']\n    size = bytes.to_f\n    unit_index = 0\n    \n    while size >= 1024 && unit_index < units.length - 1\n      size /= 1024\n      unit_index += 1\n    end\n    \n    "#{size.round(2)} #{units[unit_index]}"\n  end\nend\n\n# S\u1eed d\u1ee5ng\nAdvancedStreamCompressor.benchmark_compression_levels(\'large_dataset.csv\')\n'})}),"\n",(0,s.jsx)(e.h3,{id:"42-multi-threaded-compression",children:"4.2 Multi-threaded Compression"}),"\n",(0,s.jsx)(e.p,{children:"\u0110\u1ed1i v\u1edbi h\u1ec7 th\u1ed1ng multi-core, c\xf3 th\u1ec3 t\u0103ng t\u1ed1c b\u1eb1ng parallel processing:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:'require \'zlib\'\nrequire \'thread\'\n\nclass ParallelCompressor\n  def self.compress_multiple_files(file_list, output_dir, max_threads: 4)\n    Dir.mkdir(output_dir) unless Dir.exist?(output_dir)\n    \n    queue = Queue.new\n    file_list.each { |file| queue << file }\n    \n    threads = []\n    mutex = Mutex.new\n    completed = 0\n    \n    max_threads.times do\n      threads << Thread.new do\n        while !queue.empty?\n          begin\n            file_path = queue.pop(true) # non-blocking pop\n            output_path = File.join(output_dir, "#{File.basename(file_path)}.gz")\n            \n            compress_single_file(file_path, output_path)\n            \n            mutex.synchronize do\n              completed += 1\n              puts "Ho\xe0n th\xe0nh #{completed}/#{file_list.length}: #{File.basename(file_path)}"\n            end\n          rescue ThreadError\n            # Queue empty\n            break\n          end\n        end\n      end\n    end\n    \n    threads.each(&:join)\n    puts "N\xe9n song song ho\xe0n th\xe0nh!"\n  end\n  \n  private\n  \n  def self.compress_single_file(input_path, output_path)\n    Zlib::GzipWriter.open(output_path, Zlib::BEST_SPEED) do |gz|\n      File.open(input_path, \'rb\') do |file|\n        while chunk = file.read(16 * 1024)\n          gz.write(chunk)\n        end\n      end\n    end\n  end\nend\n\n# S\u1eed d\u1ee5ng\nfiles = Dir.glob("logs/*.log")\nParallelCompressor.compress_multiple_files(files, "compressed_logs", max_threads: 8)\n'})}),"\n",(0,s.jsx)(e.h2,{id:"best-practices-v\xe0-l\u01b0u-\xfd",children:"Best Practices v\xe0 L\u01b0u \xdd"}),"\n",(0,s.jsx)(e.h3,{id:"1-ch\u1ecdn-m\u1ee9c-\u0111\u1ed9-n\xe9n-ph\xf9-h\u1ee3p",children:"1. Ch\u1ecdn M\u1ee9c \u0110\u1ed9 N\xe9n Ph\xf9 H\u1ee3p"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:"# Cho real-time applications\nlevel = Zlib::BEST_SPEED\n\n# Cho storage/backup\nlevel = Zlib::BEST_COMPRESSION\n\n# C\xe2n b\u1eb1ng t\u1ed1c \u0111\u1ed9 v\xe0 k\xedch th\u01b0\u1edbc\nlevel = Zlib::DEFAULT_COMPRESSION\n"})}),"\n",(0,s.jsx)(e.h3,{id:"2-memory-management",children:"2. Memory Management"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:"# \u2705 T\u1ed1t: Streaming v\u1edbi chunk size h\u1ee3p l\xfd\nCHUNK_SIZE = 16 * 1024 # 16KB\n\n# \u274c Tr\xe1nh: Load to\xe0n b\u1ed9 file v\xe0o memory\ndata = File.read(large_file) # C\xf3 th\u1ec3 g\xe2y OOM\n"})}),"\n",(0,s.jsx)(e.h3,{id:"3-error-handling",children:"3. Error Handling"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-ruby",children:'def safe_compress(input_path, output_path)\n  begin\n    Zlib::GzipWriter.open(output_path) do |gz|\n      File.open(input_path, \'rb\') do |file|\n        while chunk = file.read(16 * 1024)\n          gz.write(chunk)\n        end\n      end\n    end\n    puts "N\xe9n th\xe0nh c\xf4ng: #{output_path}"\n  rescue Errno::ENOENT\n    puts "L\u1ed7i: File kh\xf4ng t\u1ed3n t\u1ea1i - #{input_path}"\n  rescue Zlib::Error => e\n    puts "L\u1ed7i compression: #{e.message}"\n    File.delete(output_path) if File.exist?(output_path)\n  rescue => e\n    puts "L\u1ed7i kh\xf4ng x\xe1c \u0111\u1ecbnh: #{e.message}"\n  end\nend\n'})}),"\n",(0,s.jsx)(e.h3,{id:"4-performance-tips",children:"4. Performance Tips"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"S\u1eed d\u1ee5ng buffer size l\xe0 b\u1ed9i s\u1ed1 c\u1ee7a 2 (16KB, 32KB, 64KB)"}),"\n",(0,s.jsx)(e.li,{children:"Ch\u1ecdn compression level ph\xf9 h\u1ee3p v\u1edbi use case"}),"\n",(0,s.jsxs)(e.li,{children:["V\u1edbi file l\u1edbn, \u01b0u ti\xean ",(0,s.jsx)(e.code,{children:"BEST_SPEED"})," \u0111\u1ec3 gi\u1ea3m CPU usage"]}),"\n",(0,s.jsx)(e.li,{children:"Monitor memory usage khi x\u1eed l\xfd file l\u1edbn"}),"\n",(0,s.jsx)(e.li,{children:"S\u1eed d\u1ee5ng parallel processing cho multiple files"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"k\u1ebft-lu\u1eadn",children:"K\u1ebft Lu\u1eadn"}),"\n",(0,s.jsx)(e.p,{children:"Compression trong Ruby l\xe0 m\u1ed9t k\u1ef9 n\u0103ng quan tr\u1ecdng cho m\u1ecdi developer. T\u1eeb vi\u1ec7c n\xe9n file \u0111\u01a1n gi\u1ea3n v\u1edbi Gzip \u0111\u1ebfn c\xe1c k\u1ef9 thu\u1eadt streaming ph\u1ee9c t\u1ea1p, Ruby cung c\u1ea5p \u0111\u1ea7y \u0111\u1ee7 c\xf4ng c\u1ee5 \u0111\u1ec3 x\u1eed l\xfd m\u1ecdi t\xecnh hu\u1ed1ng."}),"\n",(0,s.jsx)(e.p,{children:"Nh\u1eefng \u0111i\u1ec3m ch\xednh c\u1ea7n nh\u1edb:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"C\u01a1 b\u1ea3n"}),": S\u1eed d\u1ee5ng ",(0,s.jsx)(e.code,{children:"Zlib"})," cho Gzip v\xe0 ",(0,s.jsx)(e.code,{children:"rubyzip"})," cho ZIP"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Trung c\u1ea5p"}),": Streaming \u0111\u1ec3 x\u1eed l\xfd file l\u1edbn, n\xe9n in-memory cho d\u1eef li\u1ec7u t\u1ea1m"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"N\xe2ng cao"}),": TAR.GZ archives v\u1edbi metadata, parallel processing"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Expert"}),": Custom streaming v\u1edbi progress tracking v\xe0 optimization"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"H\xe3y l\u1ef1a ch\u1ecdn k\u1ef9 thu\u1eadt ph\xf9 h\u1ee3p v\u1edbi nhu c\u1ea7u c\u1ee5 th\u1ec3 c\u1ee7a d\u1ef1 \xe1n v\xe0 lu\xf4n c\xe2n nh\u1eafc gi\u1eefa t\u1ed1c \u0111\u1ed9 n\xe9n v\xe0 k\xedch th\u01b0\u1edbc file \u0111\u1ea7u ra."}),"\n",(0,s.jsx)(e.p,{children:"Ch\xfac c\xe1c b\u1ea1n \xe1p d\u1ee5ng th\xe0nh c\xf4ng c\xe1c k\u1ef9 thu\u1eadt compression trong Ruby! \ud83d\ude80"})]})}function h(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(p,{...n})}):p(n)}},65404:(n,e,i)=>{i.d(e,{R:()=>l,x:()=>o});var t=i(36672);const s={},r=t.createContext(s);function l(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:l(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);