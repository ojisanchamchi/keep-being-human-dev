"use strict";(self.webpackChunkkeep_being_human_dev=self.webpackChunkkeep_being_human_dev||[]).push([[18750],{37305:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>c,default:()=>l,frontMatter:()=>r,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"rails/active_record_migrations/expert/batch_updates_with_find_in_batches","title":"batch_updates_with_find_in_batches","description":"\ud83c\udff9 Perform Batch Updates Efficiently with findinbatches","source":"@site/docs/rails/active_record_migrations/expert/batch_updates_with_find_in_batches.md","sourceDirName":"rails/active_record_migrations/expert","slug":"/rails/active_record_migrations/expert/batch_updates_with_find_in_batches","permalink":"/keep-being-human-dev/docs/rails/active_record_migrations/expert/batch_updates_with_find_in_batches","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/rails/active_record_migrations/expert/batch_updates_with_find_in_batches.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"timestamps","permalink":"/keep-being-human-dev/docs/rails/active_record_migrations/beginner/timestamps"},"next":{"title":"custom_migration_base_class","permalink":"/keep-being-human-dev/docs/rails/active_record_migrations/expert/custom_migration_base_class"}}');var a=n(23420),s=n(65404);const r={},c=void 0,o={},d=[{value:"\ud83c\udff9 Perform Batch Updates Efficiently with <code>find_in_batches</code>",id:"-perform-batch-updates-efficiently-with-find_in_batches",level:2}];function _(e){const t={code:"code",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(t.h2,{id:"-perform-batch-updates-efficiently-with-find_in_batches",children:["\ud83c\udff9 Perform Batch Updates Efficiently with ",(0,a.jsx)(t.code,{children:"find_in_batches"})]}),"\n",(0,a.jsxs)(t.p,{children:["Updating millions of rows in a single transaction can exhaust memory or lock tables for too long. Use ",(0,a.jsx)(t.code,{children:"find_in_batches"})," with small batches:"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-ruby",children:"class NormalizeTimestampsInLogs < ActiveRecord::Migration[6.1]\n  disable_ddl_transaction!\n\n  def up\n    Log.find_in_batches(batch_size: 5_000) do |batch|\n      ids = batch.map(&:id)\n      execute <<-SQL\n        UPDATE logs\n        SET created_at = created_at AT TIME ZONE 'UTC'\n        WHERE id IN (#{ids.join(',')});\n      SQL\n    end\n  end\n\n  def down\n    # no-op or reverse logic\n  end\nend\n"})}),"\n",(0,a.jsx)(t.p,{children:"This pattern avoids huge transactions and gracefully handles large data sets."})]})}function l(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(_,{...e})}):_(e)}},65404:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>c});var i=n(36672);const a={},s=i.createContext(a);function r(e){const t=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:t},e.children)}}}]);