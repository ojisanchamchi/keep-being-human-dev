"use strict";(self.webpackChunkkeep_being_human_dev=self.webpackChunkkeep_being_human_dev||[]).push([[86345],{45537:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"ruby/serialization/advanced/streaming_large_json","title":"streaming_large_json","description":"\ud83d\udd04 Streaming Large JSON Datasets with Oj::StreamReader","source":"@site/docs/ruby/serialization/advanced/streaming_large_json.md","sourceDirName":"ruby/serialization/advanced","slug":"/ruby/serialization/advanced/streaming_large_json","permalink":"/keep-being-human-dev/docs/ruby/serialization/advanced/streaming_large_json","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ruby/serialization/advanced/streaming_large_json.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"oj_serialization_tuning","permalink":"/keep-being-human-dev/docs/ruby/serialization/advanced/oj_serialization_tuning"},"next":{"title":"json_serialization","permalink":"/keep-being-human-dev/docs/ruby/serialization/beginner/json_serialization"}}');var r=a(23420),i=a(65404);const s={},o=void 0,d={},l=[{value:"\ud83d\udd04 Streaming Large JSON Datasets with Oj::StreamReader",id:"-streaming-large-json-datasets-with-ojstreamreader",level:2}];function c(e){const n={code:"code",h2:"h2",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h2,{id:"-streaming-large-json-datasets-with-ojstreamreader",children:"\ud83d\udd04 Streaming Large JSON Datasets with Oj::StreamReader"}),"\n",(0,r.jsx)(n.p,{children:"When working with very large JSON files or streams, loading the entire document into memory can be infeasible. Oj\u2019s streaming APIs let you parse and process data incrementally, keeping memory usage low and enabling pipeline-style processing."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-ruby",children:"require 'oj'\n\nFile.open('large_items.json', 'r') do |file|\n  reader = Oj::StreamReader.new(file)\n  while reader.next\n    # Process objects under 'items' array without full load\n    if reader.path.start_with?('items')\n      item = reader.value\n      # e.g., insert into database\n      process_item(item)\n    end\n  end\nend\n"})})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},65404:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>o});var t=a(36672);const r={},i=t.createContext(r);function s(e){const n=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);