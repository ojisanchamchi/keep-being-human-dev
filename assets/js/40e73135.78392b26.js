"use strict";(self.webpackChunkkeep_being_human_dev=self.webpackChunkkeep_being_human_dev||[]).push([[10071],{65404:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>l});var i=r(36672);const a={},t=i.createContext(a);function s(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),i.createElement(t.Provider,{value:n},e.children)}},84447:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"ruby/enumerables/expert/lazy_pipeline_scaling","title":"lazy_pipeline_scaling","description":"\ud83d\ude80 Combining Multiple Lazy Enumerators for Scalable Data Pipelines","source":"@site/docs/ruby/enumerables/expert/lazy_pipeline_scaling.md","sourceDirName":"ruby/enumerables/expert","slug":"/ruby/enumerables/expert/lazy_pipeline_scaling","permalink":"/keep-being-human-dev/docs/ruby/enumerables/expert/lazy_pipeline_scaling","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ruby/enumerables/expert/lazy_pipeline_scaling.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"infinite_sequence_produce","permalink":"/keep-being-human-dev/docs/ruby/enumerables/expert/infinite_sequence_produce"},"next":{"title":"merge_infinite_streams","permalink":"/keep-being-human-dev/docs/ruby/enumerables/expert/merge_infinite_streams"}}');var a=r(23420),t=r(65404);const s={},l=void 0,o={},c=[{value:"\ud83d\ude80 Combining Multiple Lazy Enumerators for Scalable Data Pipelines",id:"-combining-multiple-lazy-enumerators-for-scalable-data-pipelines",level:2}];function p(e){const n={code:"code",h2:"h2",p:"p",pre:"pre",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h2,{id:"-combining-multiple-lazy-enumerators-for-scalable-data-pipelines",children:"\ud83d\ude80 Combining Multiple Lazy Enumerators for Scalable Data Pipelines"}),"\n",(0,a.jsxs)(n.p,{children:["When processing large or unbounded data sources, chaining ",(0,a.jsx)(n.code,{children:"Enumerator::Lazy"})," methods keeps memory usage constant by avoiding intermediate arrays. You can ",(0,a.jsx)(n.code,{children:"flat_map"})," across files, ",(0,a.jsx)(n.code,{children:"grep"})," for patterns, ",(0,a.jsx)(n.code,{children:"map"})," for transformations, and ",(0,a.jsx)(n.code,{children:"take"})," the first N elements before forcing evaluation. This approach makes complex log\u2010processing or ETL pipelines both expressive and efficient."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-ruby",children:"files = Dir['/var/log/**/*.log']\nerrors = files.lazy\n              .flat_map { |f| File.foreach(f) }\n              .grep(/ERROR/)        # filter lines matching ERROR\n              .map(&:strip)         # remove trailing newline\n              .take(500)            # limit the results\n              .force                # evaluate the pipeline\n\nputs errors.first(10)\n"})})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(p,{...e})}):p(e)}}}]);