"use strict";(self.webpackChunkkeep_being_human_dev=self.webpackChunkkeep_being_human_dev||[]).push([[65796],{26656:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>i,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"gems/ruby-openai/middle/parallel_requests","title":"parallel_requests","description":"\u26a1\ufe0f Dispatch Parallel Requests with Threads","source":"@site/docs/gems/ruby-openai/middle/parallel_requests.md","sourceDirName":"gems/ruby-openai/middle","slug":"/gems/ruby-openai/middle/parallel_requests","permalink":"/keep-being-human-dev/docs/gems/ruby-openai/middle/parallel_requests","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/gems/ruby-openai/middle/parallel_requests.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"handle_rate_limit_retries","permalink":"/keep-being-human-dev/docs/gems/ruby-openai/middle/handle_rate_limit_retries"},"next":{"title":"streaming_responses","permalink":"/keep-being-human-dev/docs/gems/ruby-openai/middle/streaming_responses"}}');var r=n(23420),a=n(65404);const i={},o=void 0,l={},d=[{value:"\u26a1\ufe0f Dispatch Parallel Requests with Threads",id:"\ufe0f-dispatch-parallel-requests-with-threads",level:2}];function u(e){const t={code:"code",h2:"h2",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.h2,{id:"\ufe0f-dispatch-parallel-requests-with-threads",children:"\u26a1\ufe0f Dispatch Parallel Requests with Threads"}),"\n",(0,r.jsx)(t.p,{children:"To speed up batch operations (e.g., summarizing multiple documents), you can fire concurrent requests using Ruby threads. This approach helps you utilize I/O waits efficiently while staying within your API rate limits."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-ruby",children:'require "ruby/openai"\n\nclient = OpenAI::Client.new\n\ndocuments = ["Doc 1 text...", "Doc 2 text...", "Doc 3 text..."]\n\nthreads = documents.map.with_index do |doc, i|\n  Thread.new do\n    response = client.chat.completions(\n      parameters: {\n        model: "gpt-3.5-turbo",\n        messages: [{ role: "user", content: "Summarize: #{doc}" }]\n      }\n    )\n    puts "Summary #{i+1}: " + response.dig("choices", 0, "message", "content")\n  end\nend\n\nthreads.each(&:join)\n'})}),"\n",(0,r.jsx)(t.p,{children:"Each thread issues an API call concurrently, reducing total elapsed time. Ensure you monitor rate usage to avoid hitting caps."})]})}function c(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(u,{...e})}):u(e)}},65404:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>o});var s=n(36672);const r={},a=s.createContext(r);function i(e){const t=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),s.createElement(a.Provider,{value:t},e.children)}}}]);