## ðŸ“¦ Buffered Chunk Reading

When processing very large files, loading the entire content into memory can lead to excessive memory pressure. Using `IO#readpartial` allows you to read a file in manageable chunks, handling slow or blocking sources gracefully. This approach is ideal for streaming parsers or when you must throttle processing rate.

```ruby
File.open('huge.log', 'r') do |file|
  buffer_size = 1024 * 1024 # 1 MB
  until file.eof?
    chunk = file.readpartial(buffer_size)
    process(chunk)  # your custom processing logic
  end
end
```

You can adjust `buffer_size` and even wrap this in an `Enumerator` for lazy pipelines.